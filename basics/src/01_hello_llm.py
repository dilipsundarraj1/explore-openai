LLM = "gpt-4o-mini"

# Set up load_dotenv()

# Call open-ai model using chat completion create.

# Print the Type and Response

# Pretty print the entire response
